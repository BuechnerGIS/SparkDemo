{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22faf714-5165-4bc2-a4e1-276da40b2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                # For working with data tables\n",
    "import geopandas as gpd            # For working with geographic data\n",
    "from shapely.geometry import Point # For creating point locations on the map\n",
    "import leafmap                     # For displaying interactive maps\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "# Step 1: Start the timer for the entire operation\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16511b06-52d8-49f9-87ba-034c35dcdb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./extracted_files/cb_2018_us_state_500k.zip',\n",
       " <http.client.HTTPMessage at 0x7f2af10b6240>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "unzip_dir = './extracted_files'\n",
    "os.makedirs(unzip_dir, exist_ok=True)\n",
    "\n",
    "# URL of the shapefile\n",
    "url = \"https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_500k.zip\"\n",
    "# Path where you want to save the zip file\n",
    "zip_path = os.path.join(unzip_dir, \"cb_2018_us_state_500k.zip\")\n",
    "\n",
    "# Download the shapefile zip\n",
    "urllib.request.urlretrieve(url, zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbdc4e3-e1f2-49e2-abc9-521ff298af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the downloaded shapefile\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05318b8-ff8a-4fb5-91cd-493b198175d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for spatial join: 0.37 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the UniversityDirectory2023 CSV\n",
    "csv_path_university = \"./UniversityData/UniversityDirectory2023.csv\"\n",
    "columns_to_use_university = [\"UNITID\", \"INSTNM\", \"ADDR\", \"CITY\", \"STABBR\", \"LONGITUD\", \"LATITUDE\"]\n",
    "df_university = pd.read_csv(csv_path_university, usecols=columns_to_use_university, encoding='ISO-8859-1')\n",
    "\n",
    "# Step 2: Load the UniversityAwardedDegrees2023 CSV\n",
    "csv_path_awarded_degrees = \"./UniversityData/UniversityAwardedDegrees2023.csv\"\n",
    "df_awarded_degrees = pd.read_csv(csv_path_awarded_degrees, usecols=[\"UNITID\", \"CTOTALT\"], encoding='ISO-8859-1')\n",
    "\n",
    "# Step 3: Merge the two DataFrames on UNITID\n",
    "df_merged = pd.merge(df_university, df_awarded_degrees, on=\"UNITID\", how=\"inner\")\n",
    "\n",
    "# Step 4: Convert LATITUDE and LONGITUD to geometry points\n",
    "def make_point(row):\n",
    "    return Point(row['LONGITUD'], row['LATITUDE'])\n",
    "df_merged['geometry'] = df_merged.apply(make_point, axis=1)\n",
    "\n",
    "# Step 5: Convert the merged DataFrame into a GeoDataFrame\n",
    "gdf_university = gpd.GeoDataFrame(df_merged, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Step 6: Load the Shapefile for US States from the correct directory\n",
    "shapefile_path = \"./extracted_files/cb_2018_us_state_500k.shp\"\n",
    "gdf_states = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Step 2: Start the timer for the spatial join\n",
    "spatial_join_start_time = time.time()\n",
    "\n",
    "# Step 7: Perform a spatial join between the university data and the state shapefile\n",
    "gdf_joined = gpd.sjoin(gdf_university, gdf_states, how=\"inner\", op=\"within\")\n",
    "\n",
    "# Step 3: Calculate and print the time taken for the spatial join\n",
    "spatial_join_end_time = time.time()\n",
    "spatial_join_duration = spatial_join_end_time - spatial_join_start_time\n",
    "print(f\"Time taken for spatial join: {spatial_join_duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf058ce-8175-4ffc-a1fc-84838f649b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATEFP   STATENS     AFFGEOID GEOID STUSPS            NAME LSAD  \\\n",
      "0      28  01779790  0400000US28    28     MS     Mississippi   00   \n",
      "1      37  01027616  0400000US37    37     NC  North Carolina   00   \n",
      "2      40  01102857  0400000US40    40     OK        Oklahoma   00   \n",
      "3      51  01779803  0400000US51    51     VA        Virginia   00   \n",
      "4      54  01779805  0400000US54    54     WV   West Virginia   00   \n",
      "\n",
      "          ALAND       AWATER  \\\n",
      "0  121533519481   3926919758   \n",
      "1  125923656064  13466071395   \n",
      "2  177662925723   3374587997   \n",
      "3  102257717110   8528531774   \n",
      "4   62266474513    489028543   \n",
      "\n",
      "                                            geometry  CTOTALT  \n",
      "0  MULTIPOLYGON (((-88.50297 30.21523, -88.49176 ...    93814  \n",
      "1  MULTIPOLYGON (((-75.72681 35.93584, -75.71827 ...   317868  \n",
      "2  POLYGON ((-103.00257 36.52659, -103.00219 36.6...   119328  \n",
      "3  MULTIPOLYGON (((-75.74241 37.80835, -75.74151 ...   285978  \n",
      "4  POLYGON ((-82.64320 38.16909, -82.64300 38.169...    75184  \n"
     ]
    }
   ],
   "source": [
    "# Step 8: Aggregate the joined data by state and sum the degrees awarded\n",
    "gdf_state_degrees = gdf_joined.groupby(\"STUSPS\")[\"CTOTALT\"].sum().reset_index()\n",
    "\n",
    "# Step 9: Merge the aggregated data back into the state boundaries GeoDataFrame\n",
    "gdf_states = gdf_states.merge(gdf_state_degrees, left_on=\"STUSPS\", right_on=\"STUSPS\", how=\"left\")\n",
    "print(gdf_states.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dc3c37-bb47-405e-9cca-b54cef61cfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9a3ea28e5c439bb0d3e7b352a3748c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.8, -96.9], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_ouâ€¦"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 10: Use the 'Name' from the shapefile for the full state names and clean up the DataFrame\n",
    "gdf_states[\"State Name\"] = gdf_states[\"NAME\"]\n",
    "gdf_states[\"State Abbreviation\"] = gdf_states[\"STUSPS\"]\n",
    "gdf_states[\"Total degrees awarded\"] = gdf_states[\"CTOTALT\"]\n",
    "\n",
    "# Drop unnecessary columns and keep the relevant ones\n",
    "gdf_states = gdf_states[[\"State Name\", \"State Abbreviation\", \"Total degrees awarded\", \"geometry\"]]\n",
    "\n",
    "# Step 11: Display the map\n",
    "# Create a map centered on the United States, with a zoom level of 4\n",
    "m = leafmap.Map(center=[37.8, -96.9], zoom=4)\n",
    "\n",
    "# Add the states with the degree totals to the map, symbolizing by the 'Total degrees awarded' column\n",
    "m.add_gdf(gdf_states, \n",
    "          layer_name=\"States with Degrees\",\n",
    "          color_by=\"Total degrees awarded\",\n",
    "          color_scale=\"YlOrRd\",\n",
    "         )\n",
    "\n",
    "# Drop unnecessary columns and keep the relevant ones\n",
    "#gdf_states = gdf_states[[\"State Name\", \"State Abbreviation\", \"Total degrees awarded\"]]\n",
    "\n",
    "m.add_labels(\n",
    "    gdf_states,\n",
    "    column=\"Total degrees awarded\",\n",
    "    label_font_size=12,\n",
    "    label_color=\"black\",\n",
    "    label_offset=[0, 0],\n",
    "    layer_name=\"Degree Labels\"\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0114229d-e15e-4422-b36e-2eae77c1c211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 303,292\n",
      "Total number of columns: 9\n",
      "Total number of cells: 2,729,628\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df_merged.shape\n",
    "num_cells = num_rows * num_columns\n",
    "\n",
    "print(f\"Total number of rows: {num_rows:,}\")\n",
    "print(f\"Total number of columns: {num_columns:,}\")\n",
    "print(f\"Total number of cells: {num_cells:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac2c82fb-6745-4d54-abfe-c61af4739ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total operation time: 6.23 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Complete the full operation\n",
    "end_time = time.time()\n",
    "total_duration = end_time - start_time\n",
    "\n",
    "# Step 5: Print the total operation time and format with commas\n",
    "print(f\"Total operation time: {total_duration:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
